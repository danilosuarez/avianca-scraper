{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0fb7b75",
   "metadata": {},
   "source": [
    "# LATAM - scraping de ofertas de vuelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304a237",
   "metadata": {},
   "source": [
    "### Notas\n",
    "- Instala Playwright y los navegadores: `pip install playwright` y luego `playwright install chromium`.\n",
    "- Ejecuta las celdas en orden; la ultima dispara `await scrape_latam_flights(...)`.\n",
    "- Ajusta rutas de guardado o progreso si trabajas en otro entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86270b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import uuid\n",
    "from datetime import datetime, timedelta, time\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright, TimeoutError, Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ecebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- CONFIGURACION --------\n",
    "BASE_URL = \"https://www.latamairlines.com\"\n",
    "MARKET_PATH = \"co/es\"  # pais/idioma\n",
    "OFFERS_PATH = \"ofertas-vuelos\"\n",
    "USER_AGENT = (\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "    \"(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    ")\n",
    "\n",
    "ORIGIN = \"BOG\"\n",
    "DESTINOS = [\"MDE\"]\n",
    "\n",
    "FECHA_INICIO = \"2025-10-29\"\n",
    "FECHA_FIN = \"2025-10-29\"\n",
    "IDA_VUELTA = False  # soporte experimental\n",
    "RETORNO_OFFSET_DIAS = 3  # usado solo si IDA_VUELTA es True\n",
    "SEARCH_TIME_UTC = time(hour=17, minute=0)\n",
    "\n",
    "ADULTOS = 1\n",
    "NINOS = 0\n",
    "BEBES = 0\n",
    "CABIN_CLASS = \"Economy\"\n",
    "REDEMPTION = \"false\"\n",
    "SORT_ORDER = \"RECOMMENDED\"\n",
    "\n",
    "REQUEST_TIMEOUT_MS = 90000\n",
    "NAVIGATION_RETRIES = 3\n",
    "NAVIGATION_RETRY_DELAY_SECONDS = 35\n",
    "WAIT_FOR_DATA_SECONDS = 45\n",
    "DOM_FALLBACK_WAIT_MS = 60000  # espera max para encontrar tarjetas en DOM\n",
    "DOM_FALLBACK_EXTRA_DELAY_MS = 3000  # pausa adicional antes de leer DOM\n",
    "\n",
    "MIN_DELAY_BETWEEN_DEST_MS = 4000\n",
    "MAX_DELAY_BETWEEN_DEST_MS = 9000\n",
    "DATE_COOLDOWN_SECONDS = 12\n",
    "LONG_PAUSE_EVERY = 12\n",
    "LONG_PAUSE_SECONDS = 35\n",
    "SAVE_PROGRESS_EVERY = 4\n",
    "\n",
    "PROGRESS_PATH = Path(\"latam_scrape_progress.json\")\n",
    "LOCAL_PARQUET_PATH = Path(\"latam_busquedas_local.parquet\")\n",
    "RAW_PAYLOAD_DIR = Path(\"latam_payloads\")\n",
    "SAVE_RAW_PAYLOADS = True\n",
    "SAVE_PRELOADED_STATE = True\n",
    "PRINT_DEBUG_FETCH = True\n",
    "DEBUG_FETCH_LIMIT = 20\n",
    "SAVE_DEBUG_FETCHES = True\n",
    "SAVE_PAGE_HTML = True\n",
    "\n",
    "HEADLESS = False  # ponlo True si quieres volver a modo headless\n",
    "BROWSER_CHANNEL = \"chrome\"  # usa None para Chromium por defecto\n",
    "BROWSER_ARGS = [\n",
    "    \"--disable-blink-features=AutomationControlled\",\n",
    "    \"--disable-dev-shm-usage\",\n",
    "    \"--disable-extensions\",\n",
    "    \"--disable-infobars\",\n",
    "    \"--no-sandbox\",\n",
    "    \"--disable-background-networking\",\n",
    "]\n",
    "\n",
    "EXTRA_HEADERS = {\n",
    "    \"sec-ch-ua\": '\"Google Chrome\";v=\"126\", \"Not.A/Brand\";v=\"8\", \"Chromium\";v=\"126\"',\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": '\"macOS\"',\n",
    "    \"accept-language\": \"es-ES,es;q=0.9,en;q=0.8\",\n",
    "    \"upgrade-insecure-requests\": \"1\",\n",
    "}\n",
    "\n",
    "INIT_JS_SCRIPTS = [\n",
    "    \"Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\",\n",
    "]\n",
    "\n",
    "PRE_LOAD_HOME = True\n",
    "COOKIE_BANNER_PATTERNS = [\"Aceptar\", \"Aceptar todo\", \"Aceptar todas\", \"Accept\", \"Allow all\"]\n",
    "COOKIE_DISMISS_SELECTORS = [\n",
    "    \"button[data-testid='cookie-banner-accept']\",\n",
    "    \"button[data-testid='cookie-banner-accept-all']\",\n",
    "]\n",
    "COOKIE_WAIT_SECONDS = 3\n",
    "SESSION_WARMUP_DELAY_MS = 3000\n",
    "\n",
    "STORAGE_STATE_PATH = Path(\"latam_storage_state.json\")\n",
    "SAVE_STORAGE_STATE = False  # ponlo True para refrescar cookies al terminar\n",
    "\n",
    "RESUME_FROM_DATE = None  # ejemplo: \"2025-10-30\"\n",
    "BROWSER_LOCALE = \"es-CO\"\n",
    "VIEWPORT = {\"width\": 1280, \"height\": 720}\n",
    "\n",
    "INTERESTING_ENDPOINT_KEYWORDS = [\n",
    "    \"air-offers\",\n",
    "    \"flight-offers\",\n",
    "    \"availability\",\n",
    "    \"journeys\",\n",
    "    \"search\",\n",
    "    \"offers\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c975c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- HELPERS --------\n",
    "\n",
    "def ensure_parent(path: Path) -> None:\n",
    "    if path is None:\n",
    "        return\n",
    "    parent = path.parent\n",
    "    if not parent.exists():\n",
    "        parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_progress(path: Path = PROGRESS_PATH) -> dict:\n",
    "    if not path or not path.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def save_progress(progress: dict, path: Path = PROGRESS_PATH) -> None:\n",
    "    if not path:\n",
    "        return\n",
    "    ensure_parent(path)\n",
    "    path.write_text(json.dumps(progress, indent=2, sort_keys=True), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def write_checkpoint_parquet(rows, path: Path = LOCAL_PARQUET_PATH) -> None:\n",
    "    if not rows:\n",
    "        return\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return\n",
    "    df = df.drop_duplicates(\n",
    "        subset=[\n",
    "            \"fecha_busqueda\",\n",
    "            \"origen_solicitado\",\n",
    "            \"destino_solicitado\",\n",
    "            \"itinerario_id\",\n",
    "            \"salida_programada\",\n",
    "        ],\n",
    "        keep=\"last\",\n",
    "    )\n",
    "    ensure_parent(path)\n",
    "    df.to_parquet(path, index=False)\n",
    "\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        yield current\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "\n",
    "def iso_with_time(date_obj, search_time=SEARCH_TIME_UTC):\n",
    "    if isinstance(search_time, str):\n",
    "        parts = search_time.split(\":\")\n",
    "        hour = int(parts[0])\n",
    "        minute = int(parts[1]) if len(parts) > 1 else 0\n",
    "        search_time = time(hour=hour, minute=minute)\n",
    "    dt = datetime.combine(date_obj, search_time)\n",
    "    return dt.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "\n",
    "\n",
    "def build_offers_url(origin, destination, departure_date, *, return_date=None, market_path=MARKET_PATH):\n",
    "    params = {\n",
    "        \"origin\": origin,\n",
    "        \"destination\": destination,\n",
    "        \"outbound\": iso_with_time(departure_date, SEARCH_TIME_UTC),\n",
    "        \"adt\": ADULTOS,\n",
    "        \"chd\": NINOS,\n",
    "        \"inf\": BEBES,\n",
    "        \"trip\": \"OW\",\n",
    "        \"cabin\": CABIN_CLASS,\n",
    "        \"redemption\": REDEMPTION,\n",
    "        \"sort\": SORT_ORDER,\n",
    "        \"exp_id\": str(uuid.uuid4()),\n",
    "    }\n",
    "    if return_date:\n",
    "        params[\"inbound\"] = iso_with_time(return_date, SEARCH_TIME_UTC)\n",
    "        params[\"trip\"] = \"RT\"\n",
    "    base = f\"{BASE_URL}/{market_path}/{OFFERS_PATH}\"\n",
    "    return f\"{base}?{urlencode(params)}\"\n",
    "\n",
    "\n",
    "def coerce_float(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "    if isinstance(value, str):\n",
    "        cleaned = value.strip().replace(\" \", \"\")\n",
    "        if not cleaned:\n",
    "            return None\n",
    "        if cleaned.count(\",\") == 1 and cleaned.count(\".\") == 0:\n",
    "            cleaned = cleaned.replace(\",\", \".\")\n",
    "        else:\n",
    "            cleaned = cleaned.replace(\",\", \"\")\n",
    "        cleaned = re.sub(r\"[^0-9.\\-]\", \"\", cleaned)\n",
    "        try:\n",
    "            return float(cleaned)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "DURATION_PATTERN = re.compile(r\"PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?\")\n",
    "\n",
    "\n",
    "def parse_duration_minutes(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, (int, float)):\n",
    "        return int(value)\n",
    "    if isinstance(value, str):\n",
    "        stripped = value.strip().upper()\n",
    "        if not stripped:\n",
    "            return None\n",
    "        if stripped.isdigit():\n",
    "            return int(stripped)\n",
    "        match = DURATION_PATTERN.fullmatch(stripped)\n",
    "        if match:\n",
    "            hours = int(match.group(1) or 0)\n",
    "            minutes = int(match.group(2) or 0)\n",
    "            seconds = int(match.group(3) or 0)\n",
    "            return hours * 60 + minutes + (1 if seconds >= 30 else 0)\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_datetime_candidate(value):\n",
    "    if not value:\n",
    "        return None\n",
    "    if isinstance(value, str):\n",
    "        return value.strip() or None\n",
    "    if isinstance(value, dict):\n",
    "        for key in (\"iso\", \"isoString\", \"utc\", \"isoUtc\", \"dateTime\", \"value\", \"text\", \"formatted\", \"display\"):\n",
    "            candidate = parse_datetime_candidate(value.get(key))\n",
    "            if candidate:\n",
    "                return candidate\n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_ts(value):\n",
    "    if not value:\n",
    "        return None\n",
    "    if isinstance(value, str) and value.endswith(\"Z\"):\n",
    "        value = value[:-1] + \"+00:00\"\n",
    "    try:\n",
    "        return datetime.fromisoformat(value)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_airport_code(segment, role):\n",
    "    node = segment.get(role)\n",
    "    if isinstance(node, dict):\n",
    "        for key in (\"code\", \"iataCode\", \"iata\", \"airportCode\"):\n",
    "            val = node.get(key)\n",
    "            if val:\n",
    "                return val\n",
    "    return segment.get(f\"{role}Code\") or segment.get(f\"{role}_code\")\n",
    "\n",
    "\n",
    "def get_carrier(segment, role=\"marketingCarrier\"):\n",
    "    node = segment.get(role)\n",
    "    if isinstance(node, dict):\n",
    "        for key in (\"code\", \"iataCode\", \"iata\", \"carrierCode\"):\n",
    "            val = node.get(key)\n",
    "            if val:\n",
    "                return val\n",
    "    value = segment.get(f\"{role}Code\")\n",
    "    if value:\n",
    "        return value\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_flight_number(segment):\n",
    "    for key in (\"flightNumber\", \"number\", \"operatingFlightNumber\", \"marketingFlightNumber\", \"flight\"):\n",
    "        value = segment.get(key)\n",
    "        if isinstance(value, dict):\n",
    "            for inner_key in (\"code\", \"number\", \"value\"):\n",
    "                inner_val = value.get(inner_key)\n",
    "                if inner_val:\n",
    "                    return str(inner_val)\n",
    "        elif value:\n",
    "            return str(value)\n",
    "    carrier = get_carrier(segment, \"marketingCarrier\") or get_carrier(segment, \"carrier\")\n",
    "    number = segment.get(\"operatingFlightNumber\") or segment.get(\"flightCode\")\n",
    "    if carrier and number:\n",
    "        return f\"{carrier}{number}\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_cabin(segment):\n",
    "    for key in (\"cabin\", \"cabinType\", \"cabinClass\", \"cabinName\"):\n",
    "        value = segment.get(key)\n",
    "        if isinstance(value, dict):\n",
    "            for inner_key in (\"code\", \"name\", \"value\"):\n",
    "                inner_val = value.get(inner_key)\n",
    "                if inner_val:\n",
    "                    return inner_val\n",
    "        elif value:\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "\n",
    "def collect_segments(itinerary):\n",
    "    segments = []\n",
    "    for container_key in (\"bounds\", \"slices\", \"journeys\"):\n",
    "        container = itinerary.get(container_key)\n",
    "        if isinstance(container, list):\n",
    "            for item in container:\n",
    "                segs = []\n",
    "                if isinstance(item, dict):\n",
    "                    segs = item.get(\"segments\") or item.get(\"legs\") or []\n",
    "                if isinstance(segs, list):\n",
    "                    segments.extend(seg for seg in segs if isinstance(seg, dict))\n",
    "    if not segments:\n",
    "        direct = itinerary.get(\"segments\") or itinerary.get(\"legs\")\n",
    "        if isinstance(direct, list):\n",
    "            segments.extend(seg for seg in direct if isinstance(seg, dict))\n",
    "    return segments\n",
    "\n",
    "\n",
    "def extract_price_info(itinerary):\n",
    "    result = {\"currency\": None, \"total\": None, \"per_pax\": None, \"raw\": None}\n",
    "\n",
    "    seen = set()\n",
    "\n",
    "    def walk(node):\n",
    "        if isinstance(node, (list, tuple)):\n",
    "            for item in node:\n",
    "                walk(item)\n",
    "            return\n",
    "        if not isinstance(node, dict):\n",
    "            return\n",
    "        node_id = id(node)\n",
    "        if node_id in seen:\n",
    "            return\n",
    "        seen.add(node_id)\n",
    "\n",
    "        currency = node.get(\"currency\") or node.get(\"currencyCode\")\n",
    "        amount = node.get(\"amount\") or node.get(\"total\") or node.get(\"value\") or node.get(\"totalAmount\")\n",
    "        if currency and not result[\"currency\"]:\n",
    "            result[\"currency\"] = currency\n",
    "        amount_value = coerce_float(amount)\n",
    "        if amount_value is not None:\n",
    "            if result[\"total\"] is None or amount_value > result[\"total\"]:\n",
    "                result[\"total\"] = amount_value\n",
    "        passenger_type = node.get(\"type\") or node.get(\"passengerType\")\n",
    "        if passenger_type and passenger_type.upper() in (\"ADT\", \"ADULT\", \"PAX\") and result[\"per_pax\"] is None:\n",
    "            result[\"per_pax\"] = amount_value\n",
    "        for key in (\"perPassenger\", \"perPassengerAmount\", \"totalByPassengerType\"):\n",
    "            value = node.get(key)\n",
    "            if isinstance(value, dict):\n",
    "                adt = value.get(\"ADT\") or value.get(\"ADULT\") or value.get(\"adult\")\n",
    "                if isinstance(adt, dict):\n",
    "                    adt_amount = coerce_float(adt.get(\"amount\") or adt.get(\"value\"))\n",
    "                    if adt_amount is not None:\n",
    "                        result[\"per_pax\"] = adt_amount\n",
    "                    currency = adt.get(\"currency\") or adt.get(\"currencyCode\")\n",
    "                    if currency and not result[\"currency\"]:\n",
    "                        result[\"currency\"] = currency\n",
    "                else:\n",
    "                    adt_amount = coerce_float(adt)\n",
    "                    if adt_amount is not None and result[\"per_pax\"] is None:\n",
    "                        result[\"per_pax\"] = adt_amount\n",
    "        for child in node.values():\n",
    "            walk(child)\n",
    "\n",
    "    walk(itinerary.get(\"price\") or itinerary.get(\"prices\") or itinerary)\n",
    "\n",
    "    if result[\"total\"] is None:\n",
    "        fares = itinerary.get(\"fares\")\n",
    "        if isinstance(fares, list):\n",
    "            for fare in fares:\n",
    "                amount_value = coerce_float(fare.get(\"amount\") or fare.get(\"totalAmount\"))\n",
    "                if amount_value is not None:\n",
    "                    result[\"total\"] = amount_value\n",
    "                    if not result[\"currency\"]:\n",
    "                        result[\"currency\"] = fare.get(\"currency\") or fare.get(\"currencyCode\")\n",
    "                    break\n",
    "\n",
    "    if result[\"per_pax\"] is None and result[\"total\"] is not None and ADULTOS:\n",
    "        result[\"per_pax\"] = result[\"total\"] / ADULTOS\n",
    "\n",
    "    result[\"raw\"] = itinerary.get(\"price\") or itinerary.get(\"prices\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_fare_brand(itinerary):\n",
    "    for key in (\"fareBrand\", \"brandCode\", \"brandId\", \"brandName\", \"fareClass\"):\n",
    "        value = itinerary.get(key)\n",
    "        if value:\n",
    "            return value\n",
    "    fares = itinerary.get(\"fares\")\n",
    "    if isinstance(fares, list):\n",
    "        for fare in fares:\n",
    "            for key in (\"brandCode\", \"brandId\", \"brandName\", \"fareBrand\"):\n",
    "                value = fare.get(key)\n",
    "                if value:\n",
    "                    return value\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_itineraries(payload):\n",
    "    itineraries = []\n",
    "    seen = set()\n",
    "    stack = [payload]\n",
    "    while stack:\n",
    "        current = stack.pop()\n",
    "        if isinstance(current, dict):\n",
    "            if \"bounds\" in current and isinstance(current[\"bounds\"], list):\n",
    "                itinerary_id = current.get(\"id\") or current.get(\"itineraryId\") or current.get(\"identifier\")\n",
    "                key = itinerary_id or id(current)\n",
    "                if key not in seen:\n",
    "                    seen.add(key)\n",
    "                    itineraries.append(current)\n",
    "            stack.extend(current.values())\n",
    "        elif isinstance(current, list):\n",
    "            stack.extend(current)\n",
    "    return itineraries\n",
    "\n",
    "\n",
    "def itinerary_to_row(itinerary, meta):\n",
    "    segments = collect_segments(itinerary)\n",
    "    if not segments:\n",
    "        return None\n",
    "\n",
    "    first_seg = segments[0]\n",
    "    last_seg = segments[-1]\n",
    "\n",
    "    departure_iso = parse_datetime_candidate(first_seg.get(\"departure\") or first_seg.get(\"departureDateTime\"))\n",
    "    arrival_iso = parse_datetime_candidate(last_seg.get(\"arrival\") or last_seg.get(\"arrivalDateTime\"))\n",
    "\n",
    "    segment_records = []\n",
    "    unique_cabins = set()\n",
    "    unique_marketing = set()\n",
    "    unique_operating = set()\n",
    "    flight_numbers = []\n",
    "\n",
    "    for seg in segments:\n",
    "        seg_dep = parse_datetime_candidate(seg.get(\"departure\") or seg.get(\"departureDateTime\"))\n",
    "        seg_arr = parse_datetime_candidate(seg.get(\"arrival\") or seg.get(\"arrivalDateTime\"))\n",
    "        duration_min = parse_duration_minutes(\n",
    "            seg.get(\"duration\")\n",
    "            or seg.get(\"durationMinutes\")\n",
    "            or seg.get(\"durationInMinutes\")\n",
    "        )\n",
    "        flight_number = get_flight_number(seg)\n",
    "        marketing = get_carrier(seg, \"marketingCarrier\") or get_carrier(seg, \"carrier\")\n",
    "        operating = get_carrier(seg, \"operatingCarrier\")\n",
    "\n",
    "        if flight_number:\n",
    "            flight_numbers.append(flight_number)\n",
    "        if marketing:\n",
    "            unique_marketing.add(marketing)\n",
    "        if operating:\n",
    "            unique_operating.add(operating)\n",
    "        cabin = get_cabin(seg)\n",
    "        if cabin:\n",
    "            unique_cabins.add(cabin)\n",
    "\n",
    "        if duration_min is None and seg_dep and seg_arr:\n",
    "            dep_dt = normalize_ts(seg_dep)\n",
    "            arr_dt = normalize_ts(seg_arr)\n",
    "            if dep_dt and arr_dt:\n",
    "                duration_min = int((arr_dt - dep_dt).total_seconds() // 60)\n",
    "\n",
    "        segment_records.append(\n",
    "            {\n",
    "                \"origen\": get_airport_code(seg, \"origin\"),\n",
    "                \"destino\": get_airport_code(seg, \"destination\"),\n",
    "                \"salida\": seg_dep,\n",
    "                \"llegada\": seg_arr,\n",
    "                \"numero_vuelo\": flight_number,\n",
    "                \"operador_marketing\": marketing,\n",
    "                \"operador_operating\": operating,\n",
    "                \"cabina\": cabin,\n",
    "                \"equipo\": seg.get(\"equipment\") or seg.get(\"aircraft\") or seg.get(\"equipmentCode\"),\n",
    "                \"duracion_min\": duration_min,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    duration_total = sum((s.get(\"duracion_min\") or 0) for s in segment_records) or None\n",
    "    if duration_total is None and departure_iso and arrival_iso:\n",
    "        dep_dt = normalize_ts(departure_iso)\n",
    "        arr_dt = normalize_ts(arrival_iso)\n",
    "        if dep_dt and arr_dt:\n",
    "            duration_total = int((arr_dt - dep_dt).total_seconds() // 60)\n",
    "\n",
    "    price_info = extract_price_info(itinerary)\n",
    "    fare_brand = extract_fare_brand(itinerary)\n",
    "\n",
    "    row = {\n",
    "        \"fecha_busqueda\": meta[\"search_date\"],\n",
    "        \"origen_solicitado\": meta[\"origin\"],\n",
    "        \"destino_solicitado\": meta[\"destination\"],\n",
    "        \"itinerario_id\": itinerary.get(\"id\") or itinerary.get(\"itineraryId\") or itinerary.get(\"identifier\"),\n",
    "        \"origen\": get_airport_code(first_seg, \"origin\"),\n",
    "        \"destino\": get_airport_code(last_seg, \"destination\"),\n",
    "        \"salida_programada\": departure_iso,\n",
    "        \"llegada_programada\": arrival_iso,\n",
    "        \"duracion_total_min\": duration_total,\n",
    "        \"numero_segmentos\": len(segment_records),\n",
    "        \"conexiones\": max(0, len(segment_records) - 1),\n",
    "        \"cabinas\": sorted(unique_cabins),\n",
    "        \"operadores_marketing\": sorted(unique_marketing),\n",
    "        \"operadores_operating\": sorted(unique_operating),\n",
    "        \"numeros_vuelo\": flight_numbers,\n",
    "        \"precio_total\": price_info[\"total\"],\n",
    "        \"precio_por_pasajero\": price_info[\"per_pax\"],\n",
    "        \"moneda\": price_info[\"currency\"],\n",
    "        \"marca_tarifa\": fare_brand,\n",
    "        \"detalle_segmentos\": json.dumps(segment_records, ensure_ascii=True),\n",
    "        \"raw_price\": json.dumps(price_info[\"raw\"], ensure_ascii=True) if price_info[\"raw\"] is not None else None,\n",
    "    }\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def extract_rows_from_journey_payload(payload, meta):\n",
    "    rows = []\n",
    "    for itinerary in find_itineraries(payload):\n",
    "        row = itinerary_to_row(itinerary, meta)\n",
    "        if row:\n",
    "            rows.append(row)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def extract_rows_from_bff_payload(payload, meta):\n",
    "    content = payload.get(\"content\")\n",
    "    if not isinstance(content, list):\n",
    "        return []\n",
    "\n",
    "    rows = []\n",
    "    for item in content:\n",
    "        summary = item.get(\"summary\") or {}\n",
    "        itinerary = item.get(\"itinerary\") or []\n",
    "        brands = summary.get(\"brands\") or []\n",
    "\n",
    "        origin_info = summary.get(\"origin\") or {}\n",
    "        destination_info = summary.get(\"destination\") or {}\n",
    "\n",
    "        departure_iso = origin_info.get(\"departure\") or None\n",
    "        arrival_iso = destination_info.get(\"arrival\") or None\n",
    "        duration_total = summary.get(\"duration\")\n",
    "\n",
    "        segment_records = []\n",
    "        flight_numbers = []\n",
    "        marketing_carriers = set()\n",
    "        operating_carriers = set()\n",
    "        cabins = set()\n",
    "\n",
    "        for seg in itinerary:\n",
    "            flight_info = seg.get(\"flight\") or {}\n",
    "            marketing = flight_info.get(\"airlineCode\")\n",
    "            operating = flight_info.get(\"operatingAirlineCode\") or flight_info.get(\"flightOperator\")\n",
    "            flight_number = flight_info.get(\"flightNumber\")\n",
    "            if flight_number is not None:\n",
    "                flight_number_str = str(flight_number)\n",
    "                if marketing:\n",
    "                    flight_numbers.append(f\"{marketing}{flight_number_str}\")\n",
    "                else:\n",
    "                    flight_numbers.append(flight_number_str)\n",
    "            if marketing:\n",
    "                marketing_carriers.add(marketing)\n",
    "            if operating:\n",
    "                operating_carriers.add(operating)\n",
    "            cabin = seg.get(\"cabinClass\")\n",
    "            if cabin:\n",
    "                cabins.add(cabin)\n",
    "\n",
    "            segment_records.append(\n",
    "                {\n",
    "                    \"origen\": seg.get(\"origin\"),\n",
    "                    \"destino\": seg.get(\"destination\"),\n",
    "                    \"salida\": seg.get(\"departure\"),\n",
    "                    \"llegada\": seg.get(\"arrival\"),\n",
    "                    \"numero_vuelo\": flight_info.get(\"flightNumber\"),\n",
    "                    \"operador_marketing\": marketing,\n",
    "                    \"operador_operating\": operating,\n",
    "                    \"cabina\": seg.get(\"cabinClass\"),\n",
    "                    \"equipo\": seg.get(\"equipment\"),\n",
    "                    \"duracion_min\": seg.get(\"duration\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if cabins:\n",
    "            cabins_readable = sorted(cabins)\n",
    "        else:\n",
    "            cabins_readable = []\n",
    "\n",
    "        if not departure_iso and segment_records:\n",
    "            departure_iso = segment_records[0].get(\"salida\")\n",
    "        if not arrival_iso and segment_records:\n",
    "            arrival_iso = segment_records[-1].get(\"llegada\")\n",
    "        if duration_total is None and segment_records:\n",
    "            durations = [seg.get(\"duracion_min\") for seg in segment_records if seg.get(\"duracion_min\") is not None]\n",
    "            if durations and all(isinstance(v, (int, float)) for v in durations):\n",
    "                duration_total = sum(int(v) for v in durations)\n",
    "\n",
    "        summary_operators = summary.get(\"flightOperators\")\n",
    "        if isinstance(summary_operators, list):\n",
    "            for op in summary_operators:\n",
    "                if op:\n",
    "                    marketing_carriers.add(op)\n",
    "\n",
    "        for brand in brands:\n",
    "            price_info = brand.get(\"price\") or {}\n",
    "            cabin_info = brand.get(\"cabin\") or {}\n",
    "            cabin_label = cabin_info.get(\"label\")\n",
    "            if cabin_label:\n",
    "                cabins_readable_brand = sorted(set(cabins_readable) | {cabin_label})\n",
    "            else:\n",
    "                cabins_readable_brand = cabins_readable\n",
    "\n",
    "            offer_id = brand.get(\"offerId\")\n",
    "            if not offer_id:\n",
    "                base_id = summary.get(\"flightCode\") or f\"{meta['search_date']}-{meta['origin']}-{meta['destination']}\"\n",
    "                offer_id = f\"{base_id}-{brand.get('id') or len(rows)}\"\n",
    "\n",
    "            row = {\n",
    "                \"fecha_busqueda\": meta[\"search_date\"],\n",
    "                \"origen_solicitado\": meta[\"origin\"],\n",
    "                \"destino_solicitado\": meta[\"destination\"],\n",
    "                \"itinerario_id\": offer_id,\n",
    "                \"origen\": origin_info.get(\"iataCode\") or (segment_records[0].get(\"origen\") if segment_records else None),\n",
    "                \"destino\": destination_info.get(\"iataCode\") or (segment_records[-1].get(\"destino\") if segment_records else None),\n",
    "                \"salida_programada\": departure_iso,\n",
    "                \"llegada_programada\": arrival_iso,\n",
    "                \"duracion_total_min\": duration_total,\n",
    "                \"numero_segmentos\": len(segment_records) if segment_records else None,\n",
    "                \"conexiones\": max(0, len(segment_records) - 1) if segment_records else None,\n",
    "                \"cabinas\": cabins_readable_brand,\n",
    "                \"operadores_marketing\": sorted(marketing_carriers) if marketing_carriers else [],\n",
    "                \"operadores_operating\": sorted(operating_carriers) if operating_carriers else [],\n",
    "                \"numeros_vuelo\": flight_numbers,\n",
    "                \"precio_total\": price_info.get(\"amount\"),\n",
    "                \"precio_por_pasajero\": price_info.get(\"amount\"),\n",
    "                \"moneda\": price_info.get(\"currency\"),\n",
    "                \"marca_tarifa\": brand.get(\"brandText\") or brand.get(\"id\"),\n",
    "                \"detalle_segmentos\": json.dumps(segment_records, ensure_ascii=True),\n",
    "                \"raw_price\": json.dumps(brand, ensure_ascii=True),\n",
    "                \"fuente\": \"json-latam\",\n",
    "            }\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def extract_rows_from_payload(payload, meta):\n",
    "    rows = []\n",
    "    if isinstance(payload, dict):\n",
    "        if payload.get(\"content\"):\n",
    "            rows.extend(extract_rows_from_bff_payload(payload, meta))\n",
    "        if payload.get(\"journeyPriceResponses\"):\n",
    "            rows.extend(extract_rows_from_journey_payload(payload, meta))\n",
    "        elif not payload.get(\"content\"):\n",
    "            rows.extend(extract_rows_from_journey_payload(payload, meta))\n",
    "    return rows\n",
    "\n",
    "\n",
    "\n",
    "DOM_TIME_PATTERN = re.compile(r\"(\\d{1,2}):(\\d{2})\\s*(a\\. m\\.|p\\. m\\.)\", re.IGNORECASE)\n",
    "DOM_DURATION_PATTERN = re.compile(r\"(?:(\\d+)\\s*h)?\\s*(?:(\\d+)\\s*(?:m|min))?\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def parse_dom_time_iso(date_iso, time_text):\n",
    "    if not time_text:\n",
    "        return None\n",
    "    text = time_text.strip().lower()\n",
    "    match = DOM_TIME_PATTERN.search(text)\n",
    "    if not match:\n",
    "        return None\n",
    "    hour = int(match.group(1))\n",
    "    minute = int(match.group(2))\n",
    "    period = match.group(3)\n",
    "    if 'p' in period and hour != 12:\n",
    "        hour += 12\n",
    "    if 'a' in period and hour == 12:\n",
    "        hour = 0\n",
    "    return f\"{date_iso}T{hour:02d}:{minute:02d}:00\"\n",
    "\n",
    "\n",
    "def parse_dom_duration_minutes(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    match = DOM_DURATION_PATTERN.search(text)\n",
    "    if not match:\n",
    "        return None\n",
    "    hours = int(match.group(1) or 0)\n",
    "    minutes = int(match.group(2) or 0)\n",
    "    total = hours * 60 + minutes\n",
    "    return total or None\n",
    "\n",
    "\n",
    "async def extract_rows_from_dom(page, meta):\n",
    "    \"\"\"Fallback: raspa informacion visible en el DOM cuando no hay payload JSON.\"\"\"\n",
    "    selector = '[data-testid=\"wrapperBoundCard\"]'\n",
    "    wait_timeout = DOM_FALLBACK_WAIT_MS or (WAIT_FOR_DATA_SECONDS * 1000)\n",
    "    try:\n",
    "        await page.wait_for_selector(selector, timeout=wait_timeout)\n",
    "    except TimeoutError:\n",
    "        print(f\"{meta['origin']}->{meta['destination']} {meta['search_date']}: DOM sin tarjetas tras {wait_timeout/1000:.1f}s\")\n",
    "        return []\n",
    "    if DOM_FALLBACK_EXTRA_DELAY_MS:\n",
    "        await page.wait_for_timeout(DOM_FALLBACK_EXTRA_DELAY_MS)\n",
    "\n",
    "    cards = page.locator(selector)\n",
    "    try:\n",
    "        count = await cards.count()\n",
    "    except Exception:\n",
    "        return []\n",
    "    if count == 0:\n",
    "        print(f\"{meta['origin']}->{meta['destination']} {meta['search_date']}: DOM sin tarjetas visibles\")\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    async def _safe_text(locator, *, timeout=1500):\n",
    "        try:\n",
    "            handle = locator.first\n",
    "            text = await handle.text_content(timeout=timeout)\n",
    "        except Exception:\n",
    "            return None\n",
    "        if text is None:\n",
    "            return None\n",
    "        return text.strip() or None\n",
    "\n",
    "    for idx in range(count):\n",
    "        card = cards.nth(idx)\n",
    "        departure_text = await _safe_text(card.locator('[data-testid=\"bound-card-departure-time\"]'))\n",
    "        arrival_text = await _safe_text(card.locator('[data-testid=\"bound-card-arrival-time\"]'))\n",
    "        duration_text = await _safe_text(card.locator('[data-testid=\"bound-card-duration\"]'))\n",
    "        flight_number_text = await _safe_text(card.locator('[data-testid=\"bound-card-flight-number\"]'))\n",
    "\n",
    "        departure_iso = parse_dom_time_iso(meta['search_date'], departure_text)\n",
    "        arrival_iso = parse_dom_time_iso(meta['search_date'], arrival_text)\n",
    "        duration_minutes = parse_dom_duration_minutes(duration_text)\n",
    "\n",
    "        base_id = f\"dom-{meta['search_date']}-{meta['origin']}-{meta['destination']}-{idx}\"\n",
    "        numeros_vuelo = []\n",
    "        if flight_number_text:\n",
    "            numeros_vuelo = [flight_number_text.replace('\\n', ' ').strip()]\n",
    "\n",
    "        dom_segment = {\n",
    "            'origen': meta['origin'],\n",
    "            'destino': meta['destination'],\n",
    "            'salida_texto': departure_text,\n",
    "            'llegada_texto': arrival_text,\n",
    "            'duracion_texto': duration_text,\n",
    "            'numero_vuelo_texto': flight_number_text,\n",
    "        }\n",
    "\n",
    "        base_row = {\n",
    "            'fecha_busqueda': meta['search_date'],\n",
    "            'origen_solicitado': meta['origin'],\n",
    "            'destino_solicitado': meta['destination'],\n",
    "            'itinerario_id': base_id,\n",
    "            'origen': meta['origin'],\n",
    "            'destino': meta['destination'],\n",
    "            'salida_programada': departure_iso,\n",
    "            'llegada_programada': arrival_iso,\n",
    "            'duracion_total_min': duration_minutes,\n",
    "            'numero_segmentos': 1 if numeros_vuelo else None,\n",
    "            'conexiones': 0 if numeros_vuelo else None,\n",
    "            'cabinas': [],\n",
    "            'operadores_marketing': [],\n",
    "            'operadores_operating': [],\n",
    "            'numeros_vuelo': numeros_vuelo,\n",
    "            'precio_total': None,\n",
    "            'precio_por_pasajero': None,\n",
    "            'moneda': None,\n",
    "            'marca_tarifa': None,\n",
    "            'detalle_segmentos': json.dumps([dom_segment], ensure_ascii=True),\n",
    "            'raw_price': None,\n",
    "            'fuente': 'dom',\n",
    "        }\n",
    "\n",
    "        fares = card.locator('[data-testid=\"fare-card\"]')\n",
    "        try:\n",
    "            fares_count = await fares.count()\n",
    "        except Exception:\n",
    "            fares_count = 0\n",
    "\n",
    "        if fares_count == 0:\n",
    "            results.append(base_row)\n",
    "            continue\n",
    "\n",
    "        for fare_idx in range(fares_count):\n",
    "            fare = fares.nth(fare_idx)\n",
    "            row = base_row.copy()\n",
    "            row['itinerario_id'] = f\"{base_id}-fare{fare_idx}\"\n",
    "            fare_name = await _safe_text(fare.locator('[data-testid=\"fare-card-fare-name\"]'))\n",
    "            if not fare_name:\n",
    "                fare_name = await _safe_text(fare.locator('[data-testid=\"fare-card-title\"]'))\n",
    "            price_text = await _safe_text(fare.locator('[data-testid=\"price-text\"]'))\n",
    "            currency_text = await _safe_text(fare.locator('[data-testid=\"price-currency\"]'))\n",
    "            row['marca_tarifa'] = fare_name\n",
    "            row['moneda'] = currency_text\n",
    "            price_value = coerce_float(price_text) if price_text else None\n",
    "            row['precio_total'] = price_value\n",
    "            row['precio_por_pasajero'] = price_value\n",
    "            dom_price = {\n",
    "                'fare_name': fare_name,\n",
    "                'price_text': price_text,\n",
    "                'currency_text': currency_text,\n",
    "            }\n",
    "            row['raw_price'] = json.dumps(dom_price, ensure_ascii=True)\n",
    "            results.append(row)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "async def goto_with_retry(page, url, *, wait_until=\"networkidle\", timeout=REQUEST_TIMEOUT_MS, retries=NAVIGATION_RETRIES):\n",
    "    attempt = 1\n",
    "    last_error = None\n",
    "    while attempt <= retries:\n",
    "        try:\n",
    "            await page.goto(url, wait_until=wait_until, timeout=timeout)\n",
    "            return\n",
    "        except (TimeoutError, Error) as exc:\n",
    "            last_error = exc\n",
    "            print(f\"[goto] intento {attempt}/{retries} fallo: {exc}\")\n",
    "            if attempt == retries:\n",
    "                raise\n",
    "            await page.wait_for_timeout(NAVIGATION_RETRY_DELAY_SECONDS * 1000)\n",
    "            attempt += 1\n",
    "    if last_error:\n",
    "        raise last_error\n",
    "\n",
    "\n",
    "async def warmup_session(page):\n",
    "    \"\"\"Carga la home y acepta cookies para inicializar cookies/tokens.\"\"\"\n",
    "    if not PRE_LOAD_HOME:\n",
    "        return\n",
    "    home_url = f\"{BASE_URL}/{MARKET_PATH}\"\n",
    "    try:\n",
    "        await goto_with_retry(page, home_url, wait_until=\"domcontentloaded\")\n",
    "    except Exception as exc:\n",
    "        print(f\"[warmup] No se pudo cargar home: {exc}\")\n",
    "        return\n",
    "    if COOKIE_WAIT_SECONDS:\n",
    "        await page.wait_for_timeout(COOKIE_WAIT_SECONDS * 1000)\n",
    "    # Intentar cerrar banner de cookies\n",
    "    for pattern in COOKIE_BANNER_PATTERNS:\n",
    "        try:\n",
    "            button = page.get_by_role(\"button\", name=re.compile(pattern, re.IGNORECASE))\n",
    "            await button.click(timeout=2000)\n",
    "            print(f\"[warmup] Banner cookies cerrado con pattern '{pattern}'\")\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "    else:\n",
    "        for selector in COOKIE_DISMISS_SELECTORS:\n",
    "            try:\n",
    "                await page.click(selector, timeout=2000)\n",
    "                print(f\"[warmup] Banner cookies cerrado con selector {selector}\")\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "    if SESSION_WARMUP_DELAY_MS:\n",
    "        await page.wait_for_timeout(SESSION_WARMUP_DELAY_MS)\n",
    "\n",
    "\n",
    "async def scrape_latam_flights(origin=ORIGIN, destinos=DESTINOS, fecha_inicio=FECHA_INICIO, fecha_fin=FECHA_FIN, ida_vuelta=IDA_VUELTA):\n",
    "    start_dt = datetime.strptime(fecha_inicio, \"%Y-%m-%d\").date()\n",
    "    end_dt = datetime.strptime(fecha_fin, \"%Y-%m-%d\").date()\n",
    "    dates = list(daterange(start_dt, end_dt))\n",
    "    if RESUME_FROM_DATE:\n",
    "        resume_dt = datetime.strptime(RESUME_FROM_DATE, \"%Y-%m-%d\").date()\n",
    "        dates = [d for d in dates if d >= resume_dt]\n",
    "\n",
    "    all_rows = []\n",
    "    progress = load_progress()\n",
    "\n",
    "    if SAVE_RAW_PAYLOADS:\n",
    "        RAW_PAYLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    async with async_playwright() as playwright:\n",
    "        browser_launch_kwargs = {\"headless\": HEADLESS}\n",
    "        if BROWSER_ARGS:\n",
    "            browser_launch_kwargs[\"args\"] = BROWSER_ARGS\n",
    "        if BROWSER_CHANNEL:\n",
    "            browser_launch_kwargs[\"channel\"] = BROWSER_CHANNEL\n",
    "        browser = await playwright.chromium.launch(**browser_launch_kwargs)\n",
    "        try:\n",
    "            context_kwargs = {\n",
    "                \"user_agent\": USER_AGENT,\n",
    "                \"locale\": BROWSER_LOCALE,\n",
    "                \"viewport\": VIEWPORT,\n",
    "            }\n",
    "            loaded_state = False\n",
    "            if STORAGE_STATE_PATH and STORAGE_STATE_PATH.exists():\n",
    "                try:\n",
    "                    context_kwargs[\"storage_state\"] = json.loads(STORAGE_STATE_PATH.read_text(encoding=\"utf-8\"))\n",
    "                    loaded_state = True\n",
    "                    print(f\"Storage state cargado desde {STORAGE_STATE_PATH}\")\n",
    "                except Exception as exc:\n",
    "                    print(f\"No se pudo cargar storage state: {exc}\")\n",
    "            context = await browser.new_context(**context_kwargs)\n",
    "            if EXTRA_HEADERS:\n",
    "                await context.set_extra_http_headers(EXTRA_HEADERS)\n",
    "            if INIT_JS_SCRIPTS:\n",
    "                for script in INIT_JS_SCRIPTS:\n",
    "                    try:\n",
    "                        await context.add_init_script(script)\n",
    "                    except Exception as exc:\n",
    "                        print(f\"No se pudo registrar init script: {exc}\")\n",
    "            try:\n",
    "                page = await context.new_page()\n",
    "                await warmup_session(page)\n",
    "                search_counter = 0\n",
    "\n",
    "                for current_date in dates:\n",
    "                    date_iso = current_date.isoformat()\n",
    "                    print(f\"===== Fecha {date_iso} =====\")\n",
    "\n",
    "                    for dest in destinos:\n",
    "                        already = progress.get(date_iso, {}).get(dest)\n",
    "                        if already is not None and already > 0:\n",
    "                            print(f\"{origin}->{dest} {date_iso}: ya registrado ({already} itinerarios)\")\n",
    "                            continue\n",
    "                        if already == 0:\n",
    "                            print(f\"{origin}->{dest} {date_iso}: registrado previamente con 0 itinerarios, reintentando\")\n",
    "\n",
    "                        return_date = None\n",
    "                        if ida_vuelta:\n",
    "                            return_date = current_date + timedelta(days=RETORNO_OFFSET_DIAS)\n",
    "\n",
    "                        search_url = build_offers_url(origin, dest, current_date, return_date=return_date)\n",
    "\n",
    "                        payloads = []\n",
    "                        response_event = asyncio.Event()\n",
    "\n",
    "                        debug_count = 0\n",
    "\n",
    "                        async def handle_response(response):\n",
    "                            nonlocal debug_count\n",
    "                            try:\n",
    "                                resource_type = response.request.resource_type\n",
    "                            except AttributeError:\n",
    "                                return\n",
    "                            if resource_type not in (\"xhr\", \"fetch\"):\n",
    "                                return\n",
    "                            url_lower = response.url.lower()\n",
    "                            keyword_match = any(keyword in url_lower for keyword in INTERESTING_ENDPOINT_KEYWORDS)\n",
    "                            if PRINT_DEBUG_FETCH and not keyword_match and debug_count < DEBUG_FETCH_LIMIT:\n",
    "                                debug_count += 1\n",
    "                                print(f\"[debug] {response.status} {response.url}\")\n",
    "                                if SAVE_DEBUG_FETCHES:\n",
    "                                    try:\n",
    "                                        text = await response.text()\n",
    "                                    except Exception:\n",
    "                                        text = None\n",
    "                                    if text:\n",
    "                                        dump_path = RAW_PAYLOAD_DIR / f\"debug_{origin}_{dest}_{date_iso}_{debug_count}.txt\"\n",
    "                                        dump_path.write_text(text, encoding=\"utf-8\", errors=\"ignore\")\n",
    "                                        print(f\"[debug] respuesta guardada en {dump_path}\")\n",
    "                            if not keyword_match:\n",
    "                                return\n",
    "                            if response.status != 200:\n",
    "                                return\n",
    "                            data = None\n",
    "                            try:\n",
    "                                data = await response.json()\n",
    "                            except Exception:\n",
    "                                try:\n",
    "                                    text = await response.text()\n",
    "                                    data = json.loads(text)\n",
    "                                except Exception:\n",
    "                                    pass\n",
    "                            if data is None:\n",
    "                                return\n",
    "                            if not any(p.get(\"url\") == response.url for p in payloads):\n",
    "                                payloads.append({\"url\": response.url, \"data\": data})\n",
    "                            if not response_event.is_set():\n",
    "                                response_event.set()\n",
    "\n",
    "                        page.on(\"response\", handle_response)\n",
    "\n",
    "                        html_dump_path = None\n",
    "                        try:\n",
    "                            await goto_with_retry(page, search_url, wait_until=\"domcontentloaded\")\n",
    "                            try:\n",
    "                                await asyncio.wait_for(response_event.wait(), timeout=WAIT_FOR_DATA_SECONDS)\n",
    "                            except asyncio.TimeoutError:\n",
    "                                print(f\"{origin}->{dest} {date_iso}: sin respuesta JSON util en {WAIT_FOR_DATA_SECONDS}s\")\n",
    "                            if not payloads:\n",
    "                                awaited_response = None\n",
    "                                try:\n",
    "                                    awaited_response = await page.wait_for_response(\n",
    "                                        lambda resp: resp.ok and any(keyword in resp.url.lower() for keyword in INTERESTING_ENDPOINT_KEYWORDS),\n",
    "                                        timeout=max(WAIT_FOR_DATA_SECONDS * 1000, DOM_FALLBACK_WAIT_MS or 0),\n",
    "                                    )\n",
    "                                except Exception:\n",
    "                                    awaited_response = None\n",
    "                                if awaited_response:\n",
    "                                    try:\n",
    "                                        data = await awaited_response.json()\n",
    "                                    except Exception:\n",
    "                                        try:\n",
    "                                            text = await awaited_response.text()\n",
    "                                            data = json.loads(text)\n",
    "                                        except Exception:\n",
    "                                            data = None\n",
    "                                    if data is not None:\n",
    "                                        if not any(p.get(\"url\") == awaited_response.url for p in payloads):\n",
    "                                            payloads.append({\"url\": awaited_response.url, \"data\": data})\n",
    "                                        if not response_event.is_set():\n",
    "                                            response_event.set()\n",
    "                            await page.wait_for_timeout(2000)\n",
    "                            if SAVE_RAW_PAYLOADS and SAVE_PAGE_HTML:\n",
    "                                try:\n",
    "                                    html = await page.content()\n",
    "                                    html_dump_path = RAW_PAYLOAD_DIR / f\"page_{origin}_{dest}_{date_iso}_{uuid.uuid4().hex}.html\"\n",
    "                                    html_dump_path.write_text(html, encoding=\"utf-8\", errors=\"ignore\")\n",
    "                                    print(f\"[debug] HTML guardado en {html_dump_path}\")\n",
    "                                except Exception as exc:\n",
    "                                    print(f\"[debug] no se guardo HTML: {exc}\")\n",
    "                        except (TimeoutError, Error) as exc:\n",
    "                            print(f\"{origin}->{dest} {date_iso}: error de navegacion {exc}\")\n",
    "                            if SAVE_RAW_PAYLOADS and SAVE_PAGE_HTML and html_dump_path is None:\n",
    "                                try:\n",
    "                                    html = await page.content()\n",
    "                                    html_dump_path = RAW_PAYLOAD_DIR / f\"page_{origin}_{dest}_{date_iso}_{uuid.uuid4().hex}.html\"\n",
    "                                    html_dump_path.write_text(html, encoding=\"utf-8\", errors=\"ignore\")\n",
    "                                    print(f\"[debug] HTML (tras error) guardado en {html_dump_path}\")\n",
    "                                except Exception:\n",
    "                                    pass\n",
    "                        finally:\n",
    "                            remover = getattr(page, \"off\", None) or getattr(page, \"remove_listener\", None)\n",
    "                            if remover:\n",
    "                                remover(\"response\", handle_response)\n",
    "\n",
    "                        candidate_payloads = [p[\"data\"] for p in payloads]\n",
    "\n",
    "                        preloaded_state = await page.evaluate(\n",
    "                            \"\"\"() => {\n",
    "                                if (typeof window === 'undefined') { return null; }\n",
    "                                const candidates = [\n",
    "                                  window.__LATAM_INITIAL_STATE__,\n",
    "                                  window.__NUXT__,\n",
    "                                  window.__INITIAL_STATE__,\n",
    "                                  window.__PRELOADED_STATE__,\n",
    "                                  window.__STATE__\n",
    "                                ];\n",
    "                                for (const item of candidates) {\n",
    "                                  if (item) {\n",
    "                                    try { return JSON.stringify(item); } catch (e) {}\n",
    "                                  }\n",
    "                                }\n",
    "                                return null;\n",
    "                            }\"\"\"\n",
    "                        )\n",
    "                        if preloaded_state:\n",
    "                            if SAVE_RAW_PAYLOADS and SAVE_PRELOADED_STATE:\n",
    "                                dump_path = RAW_PAYLOAD_DIR / f\"preloaded_{origin}_{dest}_{date_iso}_{uuid.uuid4().hex}.json\"\n",
    "                                dump_path.write_text(preloaded_state, encoding=\"utf-8\")\n",
    "                                print(f\"Estado precargado almacenado en {dump_path}\")\n",
    "                            try:\n",
    "                                candidate_payloads.append(json.loads(preloaded_state))\n",
    "                            except json.JSONDecodeError as exc:\n",
    "                                print(f\"{origin}->{dest} {date_iso}: preloaded state no parseable ({exc})\")\n",
    "\n",
    "                        meta = {\n",
    "                            \"origin\": origin,\n",
    "                            \"destination\": dest,\n",
    "                            \"search_date\": date_iso,\n",
    "                        }\n",
    "\n",
    "                        rows = []\n",
    "                        for payload in candidate_payloads:\n",
    "                            try:\n",
    "                                rows.extend(extract_rows_from_payload(payload, meta))\n",
    "                            except Exception as exc:\n",
    "                                print(f\"{origin}->{dest} {date_iso}: error extrayendo datos: {exc}\")\n",
    "\n",
    "                        if rows:\n",
    "                            for r in rows:\n",
    "                                r.setdefault(\"fuente\", \"json\")\n",
    "                            all_rows.extend(rows)\n",
    "                            progress.setdefault(date_iso, {})[dest] = len(rows)\n",
    "                            print(f\"{origin}->{dest} {date_iso}: {len(rows)} itinerarios capturados\")\n",
    "                        else:\n",
    "                            try:\n",
    "                                dom_rows = await extract_rows_from_dom(page, meta)\n",
    "                            except Error as exc:\n",
    "                                print(f\"{origin}->{dest} {date_iso}: DOM fallback fallo ({exc})\")\n",
    "                                dom_rows = []\n",
    "                            if dom_rows:\n",
    "                                all_rows.extend(dom_rows)\n",
    "                                progress.setdefault(date_iso, {})[dest] = len(dom_rows)\n",
    "                                print(f\"{origin}->{dest} {date_iso}: {len(dom_rows)} itinerarios capturados via DOM\")\n",
    "                            else:\n",
    "                                progress.setdefault(date_iso, {})[dest] = 0\n",
    "                                print(f\"{origin}->{dest} {date_iso}: sin itinerarios detectados\")\n",
    "                                if SAVE_RAW_PAYLOADS and payloads:\n",
    "                                    dump_path = RAW_PAYLOAD_DIR / f\"payload_{origin}_{dest}_{date_iso}_{uuid.uuid4().hex}.json\"\n",
    "                                    dump_path.write_text(json.dumps(payloads, indent=2, ensure_ascii=True), encoding=\"utf-8\")\n",
    "                                    print(f\"Payload almacenado en {dump_path}\")\n",
    "\n",
    "                        search_counter += 1\n",
    "\n",
    "                        if SAVE_PROGRESS_EVERY and search_counter % SAVE_PROGRESS_EVERY == 0:\n",
    "                            save_progress(progress)\n",
    "                            write_checkpoint_parquet(all_rows)\n",
    "\n",
    "                        if search_counter % LONG_PAUSE_EVERY == 0:\n",
    "                            print(f\"Pausa preventiva de {LONG_PAUSE_SECONDS}s tras {search_counter} busquedas...\")\n",
    "                            await page.wait_for_timeout(LONG_PAUSE_SECONDS * 1000)\n",
    "\n",
    "                        cooldown_ms = random.randint(MIN_DELAY_BETWEEN_DEST_MS, MAX_DELAY_BETWEEN_DEST_MS)\n",
    "                        await page.wait_for_timeout(cooldown_ms)\n",
    "\n",
    "                    if DATE_COOLDOWN_SECONDS:\n",
    "                        print(f\"Descanso post-fecha {date_iso}: {DATE_COOLDOWN_SECONDS}s\")\n",
    "                        await page.wait_for_timeout(DATE_COOLDOWN_SECONDS * 1000)\n",
    "\n",
    "                    save_progress(progress)\n",
    "                    write_checkpoint_parquet(all_rows)\n",
    "\n",
    "            finally:\n",
    "                if STORAGE_STATE_PATH and SAVE_STORAGE_STATE:\n",
    "                    try:\n",
    "                        state = await context.storage_state()\n",
    "                        STORAGE_STATE_PATH.write_text(json.dumps(state), encoding=\"utf-8\")\n",
    "                        print(f\"Storage state guardado en {STORAGE_STATE_PATH}\")\n",
    "                    except Exception as exc:\n",
    "                        print(f\"No se pudo guardar storage state: {exc}\")\n",
    "                await context.close()\n",
    "        finally:\n",
    "            await browser.close()\n",
    "\n",
    "    save_progress(progress)\n",
    "    write_checkpoint_parquet(all_rows)\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    if not df.empty:\n",
    "        df = df.drop_duplicates(\n",
    "            subset=[\n",
    "                \"fecha_busqueda\",\n",
    "                \"origen_solicitado\",\n",
    "                \"destino_solicitado\",\n",
    "                \"itinerario_id\",\n",
    "                \"salida_programada\",\n",
    "            ],\n",
    "            keep=\"last\",\n",
    "        )\n",
    "        df[\"salida_dt\"] = pd.to_datetime(df[\"salida_programada\"], errors=\"coerce\")\n",
    "        df[\"llegada_dt\"] = pd.to_datetime(df[\"llegada_programada\"], errors=\"coerce\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e62727fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage state cargado desde latam_storage_state.json\n",
      "===== Fecha 2025-10-29 =====\n",
      "BOG->MDE 2025-10-29: registrado previamente con 0 itinerarios, reintentando\n",
      "[debug] 200 https://www.latamairlines.com/es-co/flights/public/locales/es/co.json\n",
      "[debug] 200 https://www.latamairlines.com/es-co/flights/public/locales/es/common.json\n",
      "[debug] 200 https://latam.absmartly.io/v1/context?application=website&environment=Prod\n",
      "[debug] 200 https://latam.absmartly.io/v1/context?application=website&environment=Prod\n",
      "[debug] 200 https://latam.absmartly.io/v1/context?application=website&environment=Prod\n",
      "[debug] 200 https://www.google.com/ccm/collect?frm=0&tid=AW-1012797176&en=page_view&dl=https%3A%2F%2Fwww.latamairlines.com%2Fco%2Fes%2Fofertas-vuelos&scrsrc=www.googletagmanager.com&rnd=2098444868.1761835251&dt=Selecci%C3%B3n%20de%20vuelos%20%7C%20LATAM%20Airlines&auid=1064865889.1761777911&navt=n&npa=0&_tu=CA&gtm=45be5at0h2v873735880z8830161026za200zb830161026zd830161026xec&gcs=G111&gcd=13v3v3v3v5l1&dma=0&tag_exp=101509157~103116026~103200004~103233427~104527906~104528501~104684208~104684211~104948813~115480710~115583767~115938466~115938468~116217636~116217638&tft=1761835251023&tfd=935&apve=1&apvf=f\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_6.txt\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_6.txt\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_6.txt\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_6.txt\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_6.txt\n",
      "[debug] 200 https://edge.fullstory.com/s/settings/o-1N5WKS-na1/v1/web\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_7.txt\n",
      "[debug] 200 https://latam.absmartly.io/v1/context\n",
      "[debug] 200 https://latam.absmartly.io/v1/context\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_9.txt\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_9.txt\n",
      "[debug] 200 https://rs.fullstory.com/rec/page\n",
      "[debug] 200 https://gum.criteo.com/sid/json?origin=onetag&domain=latamairlines.com&sn=ChromeSyncframe&so=undefined&topUrl=www.latamairlines.com&bundle=kilLlV9UaU5uJTJGYk1wNEd3SXV0bVdGemoxZ082NFk0QWFCSmdCUmNuU0lXZ3VJNm01UXRPWUVCckhPQzB5WCUyQkdpS3Q4ZlklMkZFM0hSUnlNRGh6Sm5paGRMSHdZM1hiRUxNQjdJVlg3OE1IJTJCQ3hHdzkwQUNBYjBqd2NYeXNuZ29yMFRCV2R6WUJBcVZES3clMkJNMndkbDNYellCWUc2eExvdzJRcEQ1dnpGMlBrcFViUUlVJTNE&topicsavail=1&fledgeavail=1\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_11.txt\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_11.txt\n",
      "[debug] 200 https://resources.digital-cloud.medallia.com/wdcus/58333/forms/13684/formDataV2_1743020607843_es.json\n",
      "[debug] 200 https://resources.digital-cloud.medallia.com/wdcus/58333/forms/13929/formDataV2_1743020645607_es.json\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_13.txt\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_13.txt\n",
      "[debug] 200 https://analytics-fe.digital-cloud.medallia.com/api/web/events\n",
      "[debug] 200 https://analytics-fe.digital-cloud.medallia.com/api/web/events\n",
      "[debug] 200 https://rs.fullstory.com/rec/bundle/v2?OrgId=o-1N5WKS-na1&UserId=1b179793-521b-485b-9fe7-4d8f8533ba5f&SessionId=727ab614-3f29-45e5-9c4c-2c5ecddaab2b&PageId=be15c418-23d9-4675-881d-2438f3cfa548&Seq=5&ClientTime=1761835252476&CompiledVersion=b5f43d39d23a482e716fbd309455356a9c289795&PageStart=1761835231497&PrevBundleTime=1761835246859&IsNewSession=true&DeltaT=1930&ContentEncoding=gzip\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_16.txt\n",
      "[debug] 200 https://rs.fullstory.com/rec/bundle/v2?OrgId=o-1N5WKS-na1&UserId=1b179793-521b-485b-9fe7-4d8f8533ba5f&SessionId=727ab614-3f29-45e5-9c4c-2c5ecddaab2b&PageId=2a691cb5-d50e-40cc-a242-22e5b86a64eb&Seq=1&ClientTime=1761835253944&CompiledVersion=b5f43d39d23a482e716fbd309455356a9c289795&PageStart=1761835251432&PrevBundleTime=0&LastActivity=1253&ContentEncoding=gzip\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_17.txt\n",
      "[debug] 200 https://rs.fullstory.com/rec/bundle/v2?OrgId=o-1N5WKS-na1&UserId=1b179793-521b-485b-9fe7-4d8f8533ba5f&SessionId=727ab614-3f29-45e5-9c4c-2c5ecddaab2b&PageId=2a691cb5-d50e-40cc-a242-22e5b86a64eb&Seq=2&ClientTime=1761835256440&CompiledVersion=b5f43d39d23a482e716fbd309455356a9c289795&PageStart=1761835251432&PrevBundleTime=1761835254278&LastActivity=953&ContentEncoding=gzip\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_18.txt\n",
      "[debug] 200 https://measurement-api.criteo.com/register-trigger?partner_id=65799&uid=577f6ba8-56b1-4799-84e8-d28f9a09e455&event_name=ViewPage&islcc=0&amount_euro=0&client_side_event_id=07d909fa-fd67-45d2-9384-115ba80d7d52\n",
      "[debug] 200 https://rs.fullstory.com/rec/bundle/v2?OrgId=o-1N5WKS-na1&UserId=1b179793-521b-485b-9fe7-4d8f8533ba5f&SessionId=727ab614-3f29-45e5-9c4c-2c5ecddaab2b&PageId=2a691cb5-d50e-40cc-a242-22e5b86a64eb&Seq=3&ClientTime=1761835281442&CompiledVersion=b5f43d39d23a482e716fbd309455356a9c289795&PageStart=1761835251432&PrevBundleTime=1761835256771&LastActivity=25955&ContentEncoding=gzip\n",
      "[debug] respuesta guardada en latam_payloads/debug_BOG_MDE_2025-10-29_20.txt\n",
      "BOG->MDE 2025-10-29: sin respuesta JSON util en 45s\n",
      "[debug] HTML guardado en latam_payloads/page_BOG_MDE_2025-10-29_845c1f85f74a43da84ba18a59b198be4.html\n",
      "BOG->MDE 2025-10-29: DOM sin tarjetas tras 60.0s\n",
      "BOG->MDE 2025-10-29: sin itinerarios detectados\n",
      "Descanso post-fecha 2025-10-29: 12s\n",
      "Itinerarios capturados: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_latam = await scrape_latam_flights(ORIGIN, DESTINOS, FECHA_INICIO, FECHA_FIN, ida_vuelta=IDA_VUELTA)\n",
    "print('Itinerarios capturados:', len(df_latam))\n",
    "df_latam.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "372c6510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet local aun no existe.\n"
     ]
    }
   ],
   "source": [
    "if LOCAL_PARQUET_PATH.exists():\n",
    "    df_parquet = pd.read_parquet(LOCAL_PARQUET_PATH)\n",
    "    print('Datos en Parquet local:', len(df_parquet))\n",
    "    df_parquet.tail()\n",
    "else:\n",
    "    print('Parquet local aun no existe.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9500c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_latam_manual_once(origin=ORIGIN, destination=\"MDE\", fecha=\"2025-10-29\", *, ida_vuelta=False):\n",
    "    \"\"\"Ejecuta una sola busqueda dejando la pagina abierta para cargar manualmente.\"\"\"\n",
    "    meta = {\n",
    "        \"origin\": origin,\n",
    "        \"destination\": destination,\n",
    "        \"search_date\": fecha,\n",
    "    }\n",
    "    async with async_playwright() as playwright:\n",
    "        browser_launch_kwargs = {\"headless\": HEADLESS}\n",
    "        if BROWSER_ARGS:\n",
    "            browser_launch_kwargs[\"args\"] = BROWSER_ARGS\n",
    "        if BROWSER_CHANNEL:\n",
    "            browser_launch_kwargs[\"channel\"] = BROWSER_CHANNEL\n",
    "        browser = await playwright.chromium.launch(**browser_launch_kwargs)\n",
    "        try:\n",
    "            context_kwargs = {\n",
    "                \"user_agent\": USER_AGENT,\n",
    "                \"locale\": BROWSER_LOCALE,\n",
    "                \"viewport\": VIEWPORT,\n",
    "            }\n",
    "            if STORAGE_STATE_PATH and STORAGE_STATE_PATH.exists():\n",
    "                try:\n",
    "                    state = json.loads(STORAGE_STATE_PATH.read_text(encoding=\"utf-8\"))\n",
    "                    context_kwargs[\"storage_state\"] = state\n",
    "                    print(f\"Storage state cargado desde {STORAGE_STATE_PATH}\")\n",
    "                except Exception as exc:\n",
    "                    print(f\"No se pudo cargar storage state: {exc}\")\n",
    "            context = await browser.new_context(**context_kwargs)\n",
    "            if EXTRA_HEADERS:\n",
    "                await context.set_extra_http_headers(EXTRA_HEADERS)\n",
    "            if INIT_JS_SCRIPTS:\n",
    "                for script in INIT_JS_SCRIPTS:\n",
    "                    await context.add_init_script(script)\n",
    "            page = await context.new_page()\n",
    "            await warmup_session(page)\n",
    "            try:\n",
    "                date_obj = datetime.strptime(fecha, \"%Y-%m-%d\").date()\n",
    "                url = build_offers_url(origin, destination, date_obj, return_date=date_obj + timedelta(days=RETORNO_OFFSET_DIAS) if ida_vuelta else None)\n",
    "                print(f\"Abriendo {url}\")\n",
    "                await page.goto(url, wait_until=\"domcontentloaded\")\n",
    "                print(\"Cuando veas los vuelos en pantalla, regresa a la celda y presiona Enter para capturarlos\")\n",
    "                input(\"Presiona Enter para continuar con la extraccion via DOM  \")\n",
    "                dom_rows = await extract_rows_from_dom(page, meta)\n",
    "                print(f\"DOM rows capturados: {len(dom_rows)}\")\n",
    "                return pd.DataFrame(dom_rows)\n",
    "            finally:\n",
    "                await context.close()\n",
    "        finally:\n",
    "            await browser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fb22efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage state guardado en latam_storage_state.json\n",
      "BOG->MDE 2025-10-29: DOM sin tarjetas tras 60.0s\n",
      "DOM rows capturados: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "async def extract_from_running_chrome():\n",
    "    async with async_playwright() as pw:\n",
    "        browser = await pw.chromium.connect_over_cdp(\"http://127.0.0.1:9222\")\n",
    "        context = browser.contexts[0]           # primera ventana\n",
    "        page = context.pages[0]                 # pestaa con los vuelos\n",
    "        # Opcional: guarda storage_state para reutilizarlo luego\n",
    "        storage_state = await context.storage_state()\n",
    "        Path(\"latam_storage_state.json\").write_text(json.dumps(storage_state), encoding=\"utf-8\")\n",
    "        print(\"Storage state guardado en latam_storage_state.json\")\n",
    "\n",
    "        meta = {\n",
    "            \"origin\": ORIGIN,\n",
    "            \"destination\": DESTINOS[0],\n",
    "            \"search_date\": FECHA_INICIO,\n",
    "        }\n",
    "        dom_rows = await extract_rows_from_dom(page, meta)\n",
    "        print(f\"DOM rows capturados: {len(dom_rows)}\")\n",
    "        return pd.DataFrame(dom_rows)\n",
    "\n",
    "df_latam = await extract_from_running_chrome()\n",
    "df_latam.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fa86d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML guardado en latam_debug.html\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from pathlib import Path\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "async def dump_current_html():\n",
    "    async with async_playwright() as pw:\n",
    "        browser = await pw.chromium.connect_over_cdp(\"http://127.0.0.1:9222\")\n",
    "        context = browser.contexts[0]\n",
    "        page = context.pages[0]\n",
    "        html = await page.content()\n",
    "        Path(\"latam_debug.html\").write_text(html, encoding=\"utf-8\")\n",
    "        print(\"HTML guardado en latam_debug.html\")\n",
    "\n",
    "await dump_current_html()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45386f68",
   "metadata": {},
   "source": [
    "import asyncio\n",
    "from pathlib import Path\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "async def dump_current_html():\n",
    "    async with async_playwright() as pw:\n",
    "        browser = await pw.chromium.connect_over_cdp(\"http://127.0.0.1:9222\")\n",
    "        context = browser.contexts[0]\n",
    "        page = context.pages[0]\n",
    "        html = await page.content()\n",
    "        Path(\"latam_debug.html\").write_text(html, encoding=\"utf-8\")\n",
    "        print(\"HTML guardado en latam_debug.html\")\n",
    "\n",
    "await dump_current_html()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107dc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d777ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuevo_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
